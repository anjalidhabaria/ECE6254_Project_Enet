{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wrqIinejhkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import zipfile as zf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import cv2\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import future\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-dj3wA0jhk5"
   },
   "source": [
    "## Define the ENet model\n",
    "\n",
    "We decided to model following residual blocks as separate class to model ENET encoder and decoder:\n",
    "    - Initial block\n",
    "    - RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
    "    - ASNeck - class for asymetric bottlenecks\n",
    "    - UBNeck - class for upsampling bottlenecks\n",
    "\n",
    "ENET architecture is autoencoder based model and is divided into 5 sub-blocks. Pleas refer [ENET paper](https://arxiv.org/pdf/1606.02147.pdf) for details of each sub-block. ENET building blocks code is taken from [here](https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation).\n",
    "\n",
    "Fast scene understanding uses first 2 sub-blocks as encoder and remaining 3 as decoder. In this implemantation, there is 1 shared encoder and 3 separate decoder for 3 tasks(instance segementation, semantic segmentation, Depth estimation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "nb_dir = os.getcwd()\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ENetDecoder import ENetDecoder\n",
    "from models.ENetEncoder import ENetEncoder\n",
    "\n",
    "class BranchedENet(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        # C - number of classes\n",
    "        self.C = C\n",
    "        \n",
    "        self.enc = ENetEncoder(C)\n",
    "        \n",
    "        self.dec1 = ENetDecoder(C)\n",
    "        self.dec2 = ENetDecoder(C)\n",
    "        self.dec3 = ENetDecoder(1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Output of Encoder\n",
    "        x, i1, i2 = self.enc(x)\n",
    "        # output of all 3 decoder in list\n",
    "        #x = torch.stack([self.dec1(x, i1, i2), self.dec2(x, i1, i2), self.dec3(x, i1, i2)])\n",
    "        x = (self.dec1(x, i1, i2), self.dec2(x, i1, i2), self.dec3(x, i1, i2))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnRAXNvbjhlf"
   },
   "source": [
    "## Instantiate the ENet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Zo6pIjqjhlg"
   },
   "outputs": [],
   "source": [
    "enet = BranchedENet(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQAvwXDpjhlj"
   },
   "outputs": [],
   "source": [
    "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "enet = enet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bNQ-SAqjhky"
   },
   "source": [
    "## Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.cityscapes import Cityscapes as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 512\n",
    "width = 1024\n",
    "dataset_dir = 'data/cityscape'\n",
    "image_transform = transforms.Compose(\n",
    "        [transforms.Resize((height,width)),transforms.ToTensor()])\n",
    "train_set = dataset(dataset_dir,transform=image_transform)\n",
    "\n",
    "batch_size=2\n",
    "train_loader = data.DataLoader(train_set,batch_size=batch_size,shuffle=True,\n",
    "        num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/krefeld/krefeld_000000_014146_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/krefeld/krefeld_000000_014146_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/krefeld/krefeld_000000_014146_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/krefeld/krefeld_000000_014146_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/darmstadt/darmstadt_000084_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/darmstadt/darmstadt_000084_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/darmstadt/darmstadt_000084_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/darmstadt/darmstadt_000084_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/tubingen/tubingen_000040_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000040_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000040_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/tubingen/tubingen_000040_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/tubingen/tubingen_000023_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000023_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000023_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/tubingen/tubingen_000023_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/dusseldorf/dusseldorf_000196_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/dusseldorf/dusseldorf_000196_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/dusseldorf/dusseldorf_000196_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/dusseldorf/dusseldorf_000196_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/bremen/bremen_000139_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/bremen/bremen_000139_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/bremen/bremen_000139_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/bremen/bremen_000139_000019_disparity.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lin/.local/lib/python3.6/site-packages/torch/jit/__init__.py:1044: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[0, 11, 31, 409] (0.010448428802192211 vs. -0.0019062859937548637) and 139116 other locations (0.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "/home/lin/.local/lib/python3.6/site-packages/torch/jit/__init__.py:1044: TracerWarning: Output nr 2. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[1, 11, 47, 469] (-0.03282495588064194 vs. -0.014643089845776558) and 123184 other locations (0.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n",
      "/home/lin/.local/lib/python3.6/site-packages/torch/jit/__init__.py:1044: TracerWarning: Output nr 3. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "Not within tolerance rtol=1e-05 atol=1e-05 at input[1, 0, 47, 479] (0.0026244809851050377 vs. -0.018811669200658798) and 7897 other locations (0.00%)\n",
      "  check_tolerance, _force_outplace, True, _module_class)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/tubingen/tubingen_000053_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000053_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000053_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/tubingen/tubingen_000053_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/ulm/ulm_000050_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/ulm/ulm_000050_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/ulm/ulm_000050_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/ulm/ulm_000050_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/tubingen/tubingen_000130_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000130_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/tubingen/tubingen_000130_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/tubingen/tubingen_000130_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/bremen/bremen_000052_000019_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/bremen/bremen_000052_000019_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/bremen/bremen_000052_000019_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/bremen/bremen_000052_000019_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/strasbourg/strasbourg_000000_035255_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/strasbourg/strasbourg_000000_035255_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/strasbourg/strasbourg_000000_035255_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/strasbourg/strasbourg_000000_035255_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/hanover/hanover_000000_013205_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/hanover/hanover_000000_013205_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/hanover/hanover_000000_013205_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/hanover/hanover_000000_013205_disparity.png\n",
      "data/cityscape/leftImg8bit_trainvaltest/leftImg8bit/train/hamburg/hamburg_000000_025986_leftImg8bit.png data/cityscape/gtFine_trainvaltest/gtFine/train/hamburg/hamburg_000000_025986_gtFine_labelIds.png data/cityscape/gtFine_trainvaltest/gtFine/train/hamburg/hamburg_000000_025986_gtFine_instanceIds.png data/cityscape/disparity_trainvaltest/disparity/train/hamburg/hamburg_000000_025986_disparity.png\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "img, label, inst, dpth = dataiter.next()\n",
    "\n",
    "writer.add_graph(enet, img.to(device))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpCP5JKAjhlW"
   },
   "source": [
    "## 3 - Losses(todo)\n",
    "(1) Semantic Segmentation Loss\n",
    "\n",
    "(2) Instantance Segmentation Loss\n",
    "\n",
    "(3) Depth Estimation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "4Dv3_I_Ljhla",
    "outputId": "a4a00785-0446-46aa-edd0-6900a1d1a78d"
   },
   "outputs": [],
   "source": [
    "def inverse_huber_loss(out, target):\n",
    "    absdiff = torch.abs(out-target)\n",
    "    C = 0.2*torch.max(absdiff)\n",
    "    return torch.mean(torch.where(absdiff<C, absdiff, (absdiff*absdiff+C*C)/(2*C)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "lHm_GLNBjhld",
    "outputId": "3962711f-0616-4f3b-9570-426ec4902f9e"
   },
   "outputs": [],
   "source": [
    "def instance_loss(out, target):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxnljE48jhlm"
   },
   "source": [
    "# Step 5 and 6 has been done in dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlATaBtjjhlw"
   },
   "source": [
    "## 7 - Define the Hyperparameters(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDZLtYRbjhlw"
   },
   "outputs": [],
   "source": [
    "from data.utils import enet_weighing\n",
    "lr = 5e-4\n",
    "\n",
    "# figure out enet_weighing issue\n",
    "criterion_label = nn.CrossEntropyLoss().to(device)\n",
    "criterion_inst = criterion_label\n",
    "#criterion_inst = instance_loss\n",
    "criterion_dpth = inverse_huber_loss\n",
    "optimizer = torch.optim.Adam(enet.parameters(), \n",
    "                             lr=lr,\n",
    "                             weight_decay=2e-4)\n",
    "\n",
    "print_every = 5\n",
    "eval_every = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Odil0dEjhlz"
   },
   "source": [
    "## 8 - Training loop(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418,
     "referenced_widgets": [
      "ef1e273f3b2043b192bf81d8f4e124c5",
      "c6d5811378a4442aa4b699e457cadb69",
      "ca676c3ef7ca4d82b99142c3a287ecb7",
      "3b32064c3e2b45f9b67b2eb7c2b2bc93",
      "94113c6f17df4fa5999df7d94523af1e",
      "f41f55ceab4940c8a1533c347a19a4f2",
      "cdc46da27c4444e0b0e6f0fd8388a1b1",
      "88552b181b5f41aa94a1ca52e3bca36d"
     ]
    },
    "colab_type": "code",
    "id": "PgTjjlmxjhlz",
    "outputId": "d1272f7a-1d7e-4ceb-f8ca-68e6748cf0f3"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "bc_train = 367 // batch_size # mini_batch train\n",
    "bc_eval = 101 // batch_size  # mini_batch validation\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "2UELZ5ghjhl2",
    "outputId": "92120683-83af-44b1-ce71-ad275a5414c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 1 ---------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8529b9153a0c4640a00ce2d270e3acb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=183.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e3a5238c5c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# assign data to cpu/gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train loop\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    \n",
    "    \n",
    "    train_loss = 0\n",
    "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
    "    \n",
    "    enet.train()\n",
    "    \n",
    "    for _ in tqdm(range(bc_train)):\n",
    "        img, label, inst, dpth = dataiter.next()\n",
    "\n",
    "        # assign data to cpu/gpu\n",
    "        img, label, inst, dpth = img.to(device), label.to(device), inst.to(device), dpth.to(device)\n",
    "        label = label.squeeze(1)\n",
    "        inst = inst.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = enet(img.float())\n",
    "\n",
    "        # split output into three predictions\n",
    "        label_out, inst_out, dpth_out = out[0], out[1], out[2]\n",
    "\n",
    "        # loss calculation for class segmentation\n",
    "        loss = criterion_label(label_out, label.long()).float()\n",
    "\n",
    "        # loss calculation for class instance\n",
    "        loss += criterion_inst(inst_out, inst.long()).float()\n",
    "\n",
    "        # loss calculation for depth\n",
    "        loss += criterion_dpth(dpth_out, dpth.float())\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    writer.add_scalar('Loss/train', train_loss, e)\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        with torch.no_grad():\n",
    "            enet.eval()\n",
    "            \n",
    "            eval_loss = 0\n",
    "\n",
    "            # Validation loop\n",
    "            for _ in tqdm(range(bc_eval)):\n",
    "                img, label, inst, dpth = dataiter.next()\n",
    "                img, label, inst, dpth = img.to(device), label.to(device), inst.to(device), dpth.to(device)\n",
    "                label = label.squeeze(1)\n",
    "                inst = inst.squeeze(1)\n",
    "        \n",
    "                out = enet(img.float())\n",
    "                \n",
    "                # split output into three predictions\n",
    "                label_out, inst_out, dpth_out = out[0], out[1], out[2]\n",
    "\n",
    "                # loss calculation for class segmentation\n",
    "                eval_loss += criterion_label(label_out, label.long()).float().item()\n",
    "\n",
    "                # loss calculation for class instance\n",
    "                eval_loss += criterion_inst(inst_out, inst.long()).float().item()\n",
    "\n",
    "                # loss calculation for depth\n",
    "                eval_loss += criterion_dpth(dpth_out, dpth.float()).item()\n",
    "                \n",
    "            \n",
    "            writer.add_scalar('Loss/test', eval_loss, e // eval_every)\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : enet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, '/content/ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
    "        print ('Model saved!')\n",
    "\n",
    "print ('Epoch {}/{}...'.format(e, epochs),\n",
    "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, _, files in os.walk(folder):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

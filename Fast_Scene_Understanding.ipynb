{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wrqIinejhkt"
   },
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import future\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-dj3wA0jhk5"
   },
   "source": [
    "## Define the ENet model\n",
    "\n",
    "We decided to model following residual blocks as separate class to model ENET encoder and decoder:\n",
    "    - Initial block\n",
    "    - RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
    "    - ASNeck - class for asymetric bottlenecks\n",
    "    - UBNeck - class for upsampling bottlenecks\n",
    "\n",
    "ENET architecture is autoencoder based model and is divided into 5 sub-blocks. Pleas refer [ENET paper](https://arxiv.org/pdf/1606.02147.pdf) for details of each sub-block. ENET building blocks code is taken from [here](https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation).\n",
    "\n",
    "Fast scene understanding uses first 2 sub-blocks as encoder and remaining 3 as decoder. In this implemantation, there is 1 shared encoder and 3 separate decoder for 3 tasks(instance segementation, semantic segmentation, Depth estimation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ENetDecoder import ENetDecoder\n",
    "from models.ENetEncoder import ENetEncoder\n",
    "\n",
    "class BranchedENet(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        # C - number of classes\n",
    "        self.C = C\n",
    "        \n",
    "        self.enc = ENetEncoder(C)\n",
    "        \n",
    "        self.dec1 = ENetDecoder(C)\n",
    "        self.dec2 = ENetDecoder(C)\n",
    "        self.dec3 = ENetDecoder(C)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Output of Encoder\n",
    "        x, i1, i2 = self.enc(x)\n",
    "        # output of all 3 decoder in list\n",
    "        x = torch.stack([self.dec1(x, i1, i2), self.dec2(x, i1, i2), self.dec3(x, i1, i2)])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnRAXNvbjhlf"
   },
   "source": [
    "## Instantiate the ENet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Zo6pIjqjhlg"
   },
   "outputs": [],
   "source": [
    "enet = BranchedENet(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQAvwXDpjhlj"
   },
   "outputs": [],
   "source": [
    "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "enet = enet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bNQ-SAqjhky"
   },
   "source": [
    "## Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.cityscapes import Cityscapes as dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 512\n",
    "width = 1024\n",
    "dataset_dir = 'data/cityscape'\n",
    "image_transform = transforms.Compose(\n",
    "        [transforms.Resize((height,width)),transforms.ToTensor()])\n",
    "train_set = dataset(dataset_dir,transform=image_transform)\n",
    "\n",
    "train_loader = data.DataLoader(train_set,batch_size=1,shuffle=True,\n",
    "        num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "img, label, inst, dpth = dataiter.next()\n",
    "\n",
    "writer.add_graph(enet, img)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to add in training loop\n",
    "# writer.add_scalar('training loss',running_loss / 1000,epoch * len(trainloader) + i)\n",
    "\n",
    "# for n_iter in range(100):\n",
    "#     writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "#     writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "#     writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n",
    "#     writer.add_scalar('Accuracy/test', np.random.random(), n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpCP5JKAjhlW"
   },
   "source": [
    "## 3 - Losses(todo)\n",
    "(1) Semantic Segmentation Loss\n",
    "\n",
    "(2) Instantance Segmentation Loss\n",
    "\n",
    "(3) Depth Estimation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "0b6IvyXIjhlW",
    "outputId": "ace7c895-c043-4152-d5a5-e9339ebf6854"
   },
   "outputs": [],
   "source": [
    "# def compute_instance_cost(a_C, a_G):\n",
    "#     M = {}\n",
    "#     tools = require 'tools/tools'\n",
    "\n",
    "#     in_margin = 0.5\n",
    "#     out_margin = 1.5\n",
    "#     Lnorm = 2\n",
    "\n",
    "#     function norm(inp, L)\n",
    "#         n\n",
    "#         if (L == 1) then\n",
    "#             n = torch.sum(torch.abs(inp), 1)\n",
    "#         else\n",
    "#             n = torch.sqrt(torch.sum(torch.pow(inp, 2), 1) + 1e-8)\n",
    "#         end\n",
    "#         return n\n",
    "#     end\n",
    "\n",
    "#     -- prediction: batchsize x nDim x h x w\n",
    "#     -- labels: batchsize x classes x h x w\n",
    "\n",
    "#     local lossf =\n",
    "#         function(prediction, labels)\n",
    "#         local batchsize = prediction:size(1)\n",
    "#         local c = prediction:size(2)\n",
    "#         local height = prediction:size(3)\n",
    "#         local width = prediction:size(4)\n",
    "#         local nInstanceMaps = labels:size(2)\n",
    "#         local loss = 0\n",
    "\n",
    "#         M.loss_dist = 0\n",
    "#         M.loss_var = 0\n",
    "\n",
    "#         for b = 1, batchsize do\n",
    "#             local pred = prediction[b] -- c x h x w\n",
    "#             local loss_var = 0\n",
    "#             local loss_dist = 0\n",
    "\n",
    "#             for h = 1, nInstanceMaps do\n",
    "#                 local label = labels[b][h]:view(1, height, width) -- 1 x h x w\n",
    "#                 local means = {}\n",
    "#                 local loss_v = 0\n",
    "#                 local loss_d = 0\n",
    "\n",
    "#                 -- center pull force\n",
    "#                 for j = 1, label:max() do\n",
    "#                     local mask = label:eq(j)\n",
    "#                     local mask_sum = mask:sum()\n",
    "#                     if (mask_sum > 1) then\n",
    "#                         local inst = pred[mask:expandAs(pred)]:view(c, -1, 1) -- c x -1 x 1\n",
    "\n",
    "#                         -- Calculate mean of instance\n",
    "#                         local mean = torch.mean(inst, 2) -- c x 1 x 1\n",
    "#                         table.insert(means, mean)\n",
    "\n",
    "#                         -- Calculate variance of instance\n",
    "#                         local var = norm((inst - mean:expandAs(inst)), 2) -- 1 x -1 x 1\n",
    "#                         var = torch.cmax(var - (in_margin), 0)\n",
    "#                         local not_hinged = torch.sum(torch.gt(var, 0))\n",
    "\n",
    "#                         var = torch.pow(var, 2)\n",
    "#                         var = var:view(-1)\n",
    "\n",
    "#                         var = torch.mean(var)\n",
    "#                         loss_v = loss_v + var\n",
    "#                     end\n",
    "#                 end\n",
    "\n",
    "#                 loss_var = loss_var + loss_v\n",
    "\n",
    "#                 -- center push force\n",
    "#                 if (#means > 1) then\n",
    "#                     for j = 1, #means do\n",
    "#                         local mean_A = means[j] -- c x 1 x 1\n",
    "#                         for k = j + 1, #means do\n",
    "#                             local mean_B = means[k] -- c x 1 x 1\n",
    "#                             local d = norm(mean_A - mean_B, Lnorm) -- 1 x 1 x 1\n",
    "#                             d = torch.pow(torch.cmax(-(d - 2 * out_margin), 0), 2)\n",
    "#                             loss_d = loss_d + d[1][1][1]\n",
    "#                         end\n",
    "#                     end\n",
    "\n",
    "#                     loss_dist = loss_dist + loss_d / ((#means - 1) + 1e-8)\n",
    "#                 end\n",
    "#             end\n",
    "\n",
    "#             loss = loss + (loss_dist + loss_var)\n",
    "#         end\n",
    "\n",
    "#         loss = loss / batchsize + torch.sum(prediction) * 0\n",
    "\n",
    "#         return loss\n",
    "#     end\n",
    "\n",
    "# return lossf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "4Dv3_I_Ljhla",
    "outputId": "a4a00785-0446-46aa-edd0-6900a1d1a78d"
   },
   "outputs": [],
   "source": [
    "# def compute_huber_loss(input_i, label):\n",
    "#     local mask = label:gt(0)\n",
    "#     local d = input_i[mask] - label[mask]\n",
    "#     local ds = d:size(1)\n",
    "\n",
    "#     local da = torch.abs(d)\n",
    "#     local d2 = torch.pow(d, 2)\n",
    "\n",
    "#     local th = 1 / 5 * torch.max(da)\n",
    "#     local mask2 = torch.gt(da, th)\n",
    "#     da[mask2] = (d2[mask2] + (th * th)) / (2 * th)\n",
    "\n",
    "#     return 1 / ds * torch.sum(da)\n",
    "\n",
    "# return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "lHm_GLNBjhld",
    "outputId": "3962711f-0616-4f3b-9570-426ec4902f9e"
   },
   "outputs": [],
   "source": [
    "# local grad = require 'autograd'\n",
    "\n",
    "# def lossfunction(lossf_name, weights):\n",
    "#     if (lossf_name == 'softmaxLoss') then\n",
    "#         lossfunction = cudnn.SpatialCrossEntropyCriterion(weights)\n",
    "#     elseif (lossf_name == 'huberLoss') then\n",
    "#         lossfunction = grad.nn.AutoCriterion('depthLoss_huber')(require 'lossf/myHuberLoss')\n",
    "#     elseif (lossf_name == 'instanceLoss') then\n",
    "#         lossfunction = grad.nn.AutoCriterion('instance_loss')(require 'lossf/myInstanceLoss')\n",
    "#     else\n",
    "#         assert(false, 'Cannot load lossfunction ' .. opts.lossf)\n",
    "#     end\n",
    "\n",
    "#     return lossfunction\n",
    "# end\n",
    "\n",
    "# return getLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxnljE48jhlm"
   },
   "source": [
    "# Step 5 and 6 has been done in dataloader\n",
    "\n",
    "## 5 - Define the loader that will load the input and output images(todo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S-PxeTpjhln"
   },
   "outputs": [],
   "source": [
    "# def loader(training_path, segmented_path, batch_size, h=320, w=1000):\n",
    "#     filenames_t = os.listdir(training_path)\n",
    "#     total_files_t = len(filenames_t)\n",
    "    \n",
    "#     filenames_s = os.listdir(segmented_path)\n",
    "#     total_files_s = len(filenames_s)\n",
    "    \n",
    "#     assert(total_files_t == total_files_s)\n",
    "    \n",
    "#     if str(batch_size).lower() == 'all':\n",
    "#         batch_size = total_files_s\n",
    "    \n",
    "#     idx = 0\n",
    "#     while(1):\n",
    "#       # Choosing random indexes of images and labels\n",
    "#         batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
    "            \n",
    "        \n",
    "#         inputs = []\n",
    "#         labels = []\n",
    "        \n",
    "#         for jj in batch_idxs:\n",
    "#           # Reading normalized photo\n",
    "#             img = plt.imread(training_path + filenames_t[jj])\n",
    "#           # Resizing using nearest neighbor method\n",
    "#             img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "#             inputs.append(img)\n",
    "          \n",
    "#           # Reading semantic image\n",
    "#             img = Image.open(segmented_path + filenames_s[jj])\n",
    "#             img = np.array(img)\n",
    "#           # Resizing using nearest neighbor method\n",
    "#             img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "#             labels.append(img)\n",
    "         \n",
    "#         inputs = np.stack(inputs, axis=2)\n",
    "#       # Changing image format to C x H x W\n",
    "#         inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
    "        \n",
    "#         labels = torch.tensor(labels)\n",
    "        \n",
    "#         yield inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jyRzVwcjhlq"
   },
   "source": [
    "## 6 - Define the class weights(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIrH8GkZjhlr"
   },
   "outputs": [],
   "source": [
    "# def get_class_weights(num_classes, c=1.02):\n",
    "#     pipe = loader('images/train/', 'images/trainannot/', batch_size='all')\n",
    "#     _, labels = next(pipe)\n",
    "#     all_labels = labels.flatten()\n",
    "#     print(all_labels)\n",
    "#     each_class = np.bincount(all_labels, minlength=num_classes)\n",
    "#     prospensity_score = each_class / len(all_labels)\n",
    "#     class_weights = 1 / (np.log(c + prospensity_score))\n",
    "#     return class_weights\n",
    "\n",
    "# class_weights = get_class_weights(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlATaBtjjhlw"
   },
   "source": [
    "## 7 - Define the Hyperparameters(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDZLtYRbjhlw"
   },
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(enet.parameters(), \n",
    "                             lr=lr,\n",
    "                             weight_decay=2e-4)\n",
    "\n",
    "print_every = 5\n",
    "eval_every = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Odil0dEjhlz"
   },
   "source": [
    "## 8 - Training loop(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418,
     "referenced_widgets": [
      "ef1e273f3b2043b192bf81d8f4e124c5",
      "c6d5811378a4442aa4b699e457cadb69",
      "ca676c3ef7ca4d82b99142c3a287ecb7",
      "3b32064c3e2b45f9b67b2eb7c2b2bc93",
      "94113c6f17df4fa5999df7d94523af1e",
      "f41f55ceab4940c8a1533c347a19a4f2",
      "cdc46da27c4444e0b0e6f0fd8388a1b1",
      "88552b181b5f41aa94a1ca52e3bca36d"
     ]
    },
    "colab_type": "code",
    "id": "PgTjjlmxjhlz",
    "outputId": "d1272f7a-1d7e-4ceb-f8ca-68e6748cf0f3"
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "bc_train = 367 // batch_size # mini_batch train\n",
    "bc_eval = 101 // batch_size  # mini_batch validation\n",
    "\n",
    "# Define pipeline objects\n",
    "pipe = loader('images/train/', 'images/trainannot/', batch_size)\n",
    "eval_pipe = loader('images/val/', 'images/valannot/', batch_size)\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "2UELZ5ghjhl2",
    "outputId": "92120683-83af-44b1-ce71-ad275a5414c1"
   },
   "outputs": [],
   "source": [
    "# Train loop\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    \n",
    "    \n",
    "    train_loss = 0\n",
    "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
    "    \n",
    "    enet.train()\n",
    "    \n",
    "    for _ in tqdm(range(bc_train)):\n",
    "        X_batch, mask_batch = next(pipe)\n",
    "        \n",
    "        # assign data to cpu/gpu\n",
    "        X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = enet(X_batch.float())\n",
    "\n",
    "        # loss calculation for depth\n",
    "        loss = criterion(out[0], mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        #optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # loss calculation for class instance\n",
    "        loss = criterion(out[1], mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        #optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # loss calculation for class segmentation\n",
    "        loss = criterion(out[2], mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    print ()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (e+1) % print_every == 0:\n",
    "        print ('Epoch {}/{}...'.format(e, epochs),\n",
    "                'Loss {:6f}'.format(train_loss))\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        with torch.no_grad():\n",
    "            enet.eval()\n",
    "            \n",
    "            eval_loss = 0\n",
    "\n",
    "            # Validation loop\n",
    "            for _ in tqdm(range(bc_eval)):\n",
    "                inputs, labels = next(eval_pipe)\n",
    "\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    \n",
    "                \n",
    "                out = enet(inputs)\n",
    "                \n",
    "                out = out.data.max(1)[1]\n",
    "                \n",
    "                eval_loss += (labels.long() - out.long()).sum()\n",
    "                \n",
    "            \n",
    "            print ()\n",
    "            print ('Loss {:6f}'.format(eval_loss))\n",
    "            \n",
    "            eval_losses.append(eval_loss)\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : enet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, '/content/ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
    "        print ('Model saved!')\n",
    "\n",
    "print ('Epoch {}/{}...'.format(e, epochs),\n",
    "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnJmyQw9b1jm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path, _, files in os.walk(folder):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

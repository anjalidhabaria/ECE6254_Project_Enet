{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Fast Scene Understanding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef1e273f3b2043b192bf81d8f4e124c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6d5811378a4442aa4b699e457cadb69",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca676c3ef7ca4d82b99142c3a287ecb7",
              "IPY_MODEL_3b32064c3e2b45f9b67b2eb7c2b2bc93"
            ]
          }
        },
        "c6d5811378a4442aa4b699e457cadb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca676c3ef7ca4d82b99142c3a287ecb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_94113c6f17df4fa5999df7d94523af1e",
            "_dom_classes": [],
            "description": " 17%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 367,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f41f55ceab4940c8a1533c347a19a4f2"
          }
        },
        "3b32064c3e2b45f9b67b2eb7c2b2bc93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdc46da27c4444e0b0e6f0fd8388a1b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62/367 [00:17&lt;01:22,  3.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88552b181b5f41aa94a1ca52e3bca36d"
          }
        },
        "94113c6f17df4fa5999df7d94523af1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f41f55ceab4940c8a1533c347a19a4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdc46da27c4444e0b0e6f0fd8388a1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88552b181b5f41aa94a1ca52e3bca36d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wrqIinejhkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile as zf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bNQ-SAqjhky",
        "colab_type": "text"
      },
      "source": [
        "## 1 - Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24VBWq_jhkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget https://www.dropbox.com/s/pxcz2wdz04zxocq/CamVid.zip?dl=1 -O CamVid.zip\n",
        "#!unzip CamVid.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdA2ZHq4jhk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip CamVid.zip -d images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-dj3wA0jhk5",
        "colab_type": "text"
      },
      "source": [
        "## 2 - Create the ENet model\n",
        "Major ENet code is borrowed from iArunava/ENet-Real-Time-Semantic-Segmentation\n",
        "We decided to to split the model to three sub classes:\n",
        "\n",
        "1) Initial block\n",
        "\n",
        "2) RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
        "\n",
        "3) ASNeck - class for asymetric bottlenecks\n",
        "\n",
        "4) UBNeck - class for upsampling bottlenecks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ2tXkJVjhk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InitialBlock(nn.Module):\n",
        "  \n",
        "  # Initial block of the model:\n",
        "  #         Input\n",
        "  #        /     \\\n",
        "  #       /       \\\n",
        "  #maxpool2d    conv2d-3x3\n",
        "  #       \\       /  \n",
        "  #        \\     /\n",
        "  #      concatenate\n",
        "   \n",
        "    def __init__ (self,in_channels = 3,out_channels = 13):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=2, \n",
        "                                      stride = 2, \n",
        "                                      padding = 0)\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, \n",
        "                                out_channels,\n",
        "                                kernel_size = 3,\n",
        "                                stride = 2, \n",
        "                                padding = 1)\n",
        "\n",
        "        self.prelu = nn.PReLU(16)\n",
        "\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "  \n",
        "    def forward(self, x):\n",
        "        \n",
        "        main = self.conv(x)\n",
        "        main = self.batchnorm(main)\n",
        "        \n",
        "        side = self.maxpool(x)\n",
        "        \n",
        "        # concatenating on the channels axis\n",
        "        x = torch.cat((main, side), dim=1)\n",
        "        x = self.prelu(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHQIix9Pjhk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RDDNeck(nn.Module):\n",
        "    def __init__(self, dilation, in_channels, out_channels, down_flag, relu=False, projection_ratio=4, p=0.1):\n",
        "      \n",
        "  # Regular|Dilated|Downsampling bottlenecks:\n",
        "  #\n",
        "  #     Bottleneck Input\n",
        "  #        /        \\\n",
        "  #       /          \\\n",
        "  # maxpooling2d   conv2d-1x1\n",
        "  #      |             | PReLU\n",
        "  #      |         conv2d-3x3\n",
        "  #      |             | PReLU\n",
        "  #      |         conv2d-1x1\n",
        "  #      |             |\n",
        "  #  Padding2d     Regularizer\n",
        "  #       \\           /  \n",
        "  #        \\         /\n",
        "  #      Summing + PReLU\n",
        "  #\n",
        "  # Params: \n",
        "  #  dilation (bool) - if True: creating dilation bottleneck\n",
        "  #  down_flag (bool) - if True: creating downsampling bottleneck\n",
        "  #  projection_ratio - ratio between input and output channels\n",
        "  #  relu - if True: relu used as the activation function else: Prelu us used\n",
        "  #  p - dropout ratio\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # Define class variables\n",
        "        self.in_channels = in_channels\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        self.dilation = dilation\n",
        "        self.down_flag = down_flag\n",
        "        \n",
        "        # calculating the number of reduced channels\n",
        "        if down_flag:\n",
        "            self.stride = 2\n",
        "            self.reduced_depth = int(in_channels // projection_ratio)\n",
        "        else:\n",
        "            self.stride = 1\n",
        "            self.reduced_depth = int(out_channels // projection_ratio)\n",
        "        \n",
        "        if relu:\n",
        "            activation = nn.ReLU()\n",
        "        else:\n",
        "            activation = nn.PReLU()\n",
        "        \n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 2,\n",
        "                                      stride = 2,\n",
        "                                      padding = 0, return_indices=True)\n",
        "        \n",
        "\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(p=p)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n",
        "                               out_channels = self.reduced_depth,\n",
        "                               kernel_size = 1,\n",
        "                               stride = 1,\n",
        "                               padding = 0,\n",
        "                               bias = False,\n",
        "                               dilation = 1)\n",
        "        \n",
        "        self.prelu1 = activation\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.reduced_depth,\n",
        "                                  kernel_size = 3,\n",
        "                                  stride = self.stride,\n",
        "                                  padding = self.dilation,\n",
        "                                  bias = True,\n",
        "                                  dilation = self.dilation)\n",
        "                                  \n",
        "        self.prelu2 = activation\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.out_channels,\n",
        "                                  kernel_size = 1,\n",
        "                                  stride = 1,\n",
        "                                  padding = 0,\n",
        "                                  bias = False,\n",
        "                                  dilation = 1)\n",
        "        \n",
        "        self.prelu3 = activation\n",
        "        \n",
        "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        bs = x.size()[0]\n",
        "        x_copy = x\n",
        "        \n",
        "        # Side Branch\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.prelu1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.prelu2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm2(x)\n",
        "                \n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Main Branch\n",
        "        if self.down_flag:\n",
        "            x_copy, indices = self.maxpool(x_copy)\n",
        "          \n",
        "        if self.in_channels != self.out_channels:\n",
        "            out_shape = self.out_channels - self.in_channels\n",
        "            \n",
        "            #padding and concatenating in order to match the channels axis of the side and main branches\n",
        "            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n",
        "            if torch.cuda.is_available():\n",
        "                extras = extras.cuda()\n",
        "            x_copy = torch.cat((x_copy, extras), dim = 1)\n",
        "\n",
        "        # Summing main and side branches\n",
        "        x = x + x_copy\n",
        "        x = self.prelu3(x)\n",
        "        \n",
        "        if self.down_flag:\n",
        "            return x, indices\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KPH7yKPjhk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASNeck(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, projection_ratio=4):\n",
        "      \n",
        "  # Asymetric bottleneck:\n",
        "  #\n",
        "  #     Bottleneck Input\n",
        "  #        /        \\\n",
        "  #       /          \\\n",
        "  #      |         conv2d-1x1\n",
        "  #      |             | PReLU\n",
        "  #      |         conv2d-1x5\n",
        "  #      |             |\n",
        "  #      |         conv2d-5x1\n",
        "  #      |             | PReLU\n",
        "  #      |         conv2d-1x1\n",
        "  #      |             |\n",
        "  #  Padding2d     Regularizer\n",
        "  #       \\           /  \n",
        "  #        \\         /\n",
        "  #      Summing + PReLU\n",
        "  #\n",
        "  # Params:    \n",
        "  #  projection_ratio - ratio between input and output channels\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # Define class variables\n",
        "        self.in_channels = in_channels\n",
        "        self.reduced_depth = int(in_channels / projection_ratio)\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(p=0.1)\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n",
        "                               out_channels = self.reduced_depth,\n",
        "                               kernel_size = 1,\n",
        "                               stride = 1,\n",
        "                               padding = 0,\n",
        "                               bias = False)\n",
        "        \n",
        "        self.prelu1 = nn.PReLU()\n",
        "        \n",
        "        self.conv21 = nn.Conv2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.reduced_depth,\n",
        "                                  kernel_size = (1, 5),\n",
        "                                  stride = 1,\n",
        "                                  padding = (0, 2),\n",
        "                                  bias = False)\n",
        "        \n",
        "        self.conv22 = nn.Conv2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.reduced_depth,\n",
        "                                  kernel_size = (5, 1),\n",
        "                                  stride = 1,\n",
        "                                  padding = (2, 0),\n",
        "                                  bias = False)\n",
        "        \n",
        "        self.prelu2 = nn.PReLU()\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.out_channels,\n",
        "                                  kernel_size = 1,\n",
        "                                  stride = 1,\n",
        "                                  padding = 0,\n",
        "                                  bias = False)\n",
        "        \n",
        "        self.prelu3 = nn.PReLU()\n",
        "        \n",
        "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs = x.size()[0]\n",
        "        x_copy = x\n",
        "        \n",
        "        # Side Branch\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.prelu1(x)\n",
        "        \n",
        "        x = self.conv21(x)\n",
        "        x = self.conv22(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.prelu2(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "                \n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        \n",
        "        # Main Branch\n",
        "        \n",
        "        if self.in_channels != self.out_channels:\n",
        "            out_shape = self.out_channels - self.in_channels\n",
        "            \n",
        "            #padding and concatenating in order to match the channels axis of the side and main branches\n",
        "            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n",
        "            if torch.cuda.is_available():\n",
        "                extras = extras.cuda()\n",
        "            x_copy = torch.cat((x_copy, extras), dim = 1)\n",
        "        \n",
        "        # Summing main and side branches\n",
        "        x = x + x_copy\n",
        "        x = self.prelu3(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXbz-4SOjhlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UBNeck(nn.Module):\n",
        "    \n",
        "  # Upsampling bottleneck:\n",
        "  #     Bottleneck Input\n",
        "  #        /        \\\n",
        "  #       /          \\\n",
        "  # conv2d-1x1     convTrans2d-1x1\n",
        "  #      |             | PReLU\n",
        "  #      |         convTrans2d-3x3\n",
        "  #      |             | PReLU\n",
        "  #      |         convTrans2d-1x1\n",
        "  #      |             |\n",
        "  # maxunpool2d    Regularizer\n",
        "  #       \\           /  \n",
        "  #        \\         /\n",
        "  #      Summing + PReLU\n",
        "  #\n",
        "  #  Params: \n",
        "  #  projection_ratio - ratio between input and output channels\n",
        "  #  relu - if True: relu used as the activation function else: Prelu us used\n",
        "  \n",
        "    def __init__(self, in_channels, out_channels, relu=False, projection_ratio=4):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        # Define class variables\n",
        "        self.in_channels = in_channels\n",
        "        self.reduced_depth = int(in_channels / projection_ratio)\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "        \n",
        "        if relu:\n",
        "            activation = nn.ReLU()\n",
        "        else:\n",
        "            activation = nn.PReLU()\n",
        "        \n",
        "        self.unpool = nn.MaxUnpool2d(kernel_size = 2,\n",
        "                                     stride = 2)\n",
        "        \n",
        "        self.main_conv = nn.Conv2d(in_channels = self.in_channels,\n",
        "                                    out_channels = self.out_channels,\n",
        "                                    kernel_size = 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout2d(p=0.1)\n",
        "        \n",
        "        \n",
        "        self.convt1 = nn.ConvTranspose2d(in_channels = self.in_channels,\n",
        "                               out_channels = self.reduced_depth,\n",
        "                               kernel_size = 1,\n",
        "                               padding = 0,\n",
        "                               bias = False)\n",
        "        \n",
        "        \n",
        "        self.prelu1 = activation\n",
        "        \n",
        "        # This layer used for Upsampling\n",
        "        self.convt2 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.reduced_depth,\n",
        "                                  kernel_size = 3,\n",
        "                                  stride = 2,\n",
        "                                  padding = 1,\n",
        "                                  output_padding = 1,\n",
        "                                  bias = False)\n",
        "        \n",
        "        self.prelu2 = activation\n",
        "        \n",
        "        self.convt3 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n",
        "                                  out_channels = self.out_channels,\n",
        "                                  kernel_size = 1,\n",
        "                                  padding = 0,\n",
        "                                  bias = False)\n",
        "        \n",
        "        self.prelu3 = activation\n",
        "        \n",
        "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
        "        \n",
        "    def forward(self, x, indices):\n",
        "        x_copy = x\n",
        "        \n",
        "        # Side Branch\n",
        "        x = self.convt1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.prelu1(x)\n",
        "        \n",
        "        x = self.convt2(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.prelu2(x)\n",
        "        \n",
        "        x = self.convt3(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Main Branch\n",
        "        \n",
        "        x_copy = self.main_conv(x_copy)\n",
        "        x_copy = self.unpool(x_copy, indices, output_size=x.size())\n",
        "        \n",
        "        # summing the main and side branches\n",
        "        x = x + x_copy\n",
        "        x = self.prelu3(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrFQWeggjhlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ENet(nn.Module):\n",
        "  \n",
        "  # Creating Enet model!\n",
        "  \n",
        "    def __init__(self, C):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Define class variables\n",
        "        # C - number of classes\n",
        "        self.C = C\n",
        "        \n",
        "        # The initial block\n",
        "        self.init = InitialBlock()\n",
        "        \n",
        "        \n",
        "        # The first bottleneck\n",
        "        self.b10 = RDDNeck(dilation=1, \n",
        "                           in_channels=16, \n",
        "                           out_channels=64, \n",
        "                           down_flag=True, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b11 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b12 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b13 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b14 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        \n",
        "        # The second bottleneck\n",
        "        self.b20 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=128, \n",
        "                           down_flag=True)\n",
        "        \n",
        "        self.b21 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b22 = RDDNeck(dilation=2, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b23 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b24 = RDDNeck(dilation=4, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b25 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b26 = RDDNeck(dilation=8, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b27 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b28 = RDDNeck(dilation=16, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        \n",
        "        # The third bottleneck\n",
        "        self.b31 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b32 = RDDNeck(dilation=2, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b33 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b34 = RDDNeck(dilation=4, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b35 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b36 = RDDNeck(dilation=8, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b37 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b38 = RDDNeck(dilation=16, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        \n",
        "        # The fourth bottleneck\n",
        "        self.b40 = UBNeck(in_channels=128, \n",
        "                          out_channels=64, \n",
        "                          relu=True)\n",
        "        \n",
        "        self.b41 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           relu=True)\n",
        "        \n",
        "        self.b42 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           relu=True)\n",
        "        \n",
        "        \n",
        "        # The fifth bottleneck\n",
        "        self.b50 = UBNeck(in_channels=64, \n",
        "                          out_channels=16, \n",
        "                          relu=True)\n",
        "        \n",
        "        self.b51 = RDDNeck(dilation=1, \n",
        "                           in_channels=16, \n",
        "                           out_channels=16, \n",
        "                           down_flag=False, \n",
        "                           relu=True)\n",
        "        \n",
        "        \n",
        "        # Final ConvTranspose Layer\n",
        "        self.fullconv = nn.ConvTranspose2d(in_channels=16, \n",
        "                                           out_channels=self.C, \n",
        "                                           kernel_size=3, \n",
        "                                           stride=2, \n",
        "                                           padding=1, \n",
        "                                           output_padding=1,\n",
        "                                           bias=False)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # The initial block\n",
        "        x = self.init(x)\n",
        "        \n",
        "        # The first bottleneck\n",
        "        x, i1 = self.b10(x)\n",
        "        x = self.b11(x)\n",
        "        x = self.b12(x)\n",
        "        x = self.b13(x)\n",
        "        x = self.b14(x)\n",
        "        \n",
        "        # The second bottleneck\n",
        "        x, i2 = self.b20(x)\n",
        "        x = self.b21(x)\n",
        "        x = self.b22(x)\n",
        "        x = self.b23(x)\n",
        "        x = self.b24(x)\n",
        "        x = self.b25(x)\n",
        "        x = self.b26(x)\n",
        "        x = self.b27(x)\n",
        "        x = self.b28(x)\n",
        "\n",
        "        # The third bottleneck\n",
        "        x = self.b31(x)\n",
        "        x = self.b32(x)\n",
        "        x = self.b33(x)\n",
        "        x = self.b34(x)\n",
        "        x = self.b35(x)\n",
        "        x = self.b36(x)\n",
        "        x = self.b37(x)\n",
        "        x = self.b38(x)\n",
        "        \n",
        "        # The fourth bottleneck\n",
        "        x = self.b40(x, i2)\n",
        "        x = self.b41(x)\n",
        "        x = self.b42(x)\n",
        "        \n",
        "        # The fifth bottleneck\n",
        "        x = self.b50(x, i1)\n",
        "        x = self.b51(x)\n",
        "        \n",
        "        # Final ConvTranspose Layer\n",
        "        x = self.fullconv(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeDTxGHDjhlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ENetDecoder(nn.Module):\n",
        "    # Creating Branched Enet model!\n",
        "  \n",
        "    def __init__(self, C):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Define class variables\n",
        "        # C - number of classes\n",
        "        self.C = C    \n",
        "        \n",
        "         \n",
        "        # The third bottleneck\n",
        "        self.b31 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b32 = RDDNeck(dilation=2, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b33 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b34 = RDDNeck(dilation=4, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b35 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b36 = RDDNeck(dilation=8, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b37 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b38 = RDDNeck(dilation=16, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        \n",
        "        # The fourth bottleneck\n",
        "        self.b40 = UBNeck(in_channels=128, \n",
        "                          out_channels=64, \n",
        "                          relu=True)\n",
        "        \n",
        "        self.b41 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, #originally 64\n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           relu=True)\n",
        "        \n",
        "        self.b42 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           relu=True)\n",
        "        \n",
        "        \n",
        "        # The fifth bottleneck\n",
        "        self.b50 = UBNeck(in_channels=64, \n",
        "                          out_channels=16, \n",
        "                          relu=True)\n",
        "        \n",
        "        self.b51 = RDDNeck(dilation=1, \n",
        "                           in_channels=16, # originally 16\n",
        "                           out_channels=16, \n",
        "                           down_flag=False, \n",
        "                           relu=True)\n",
        "        \n",
        "        \n",
        "        # Final ConvTranspose Layer\n",
        "        self.fullconv = nn.ConvTranspose2d(in_channels=16, \n",
        "                                           out_channels=self.C, \n",
        "                                           kernel_size=3, \n",
        "                                           stride=2, \n",
        "                                           padding=1, \n",
        "                                           output_padding=1,\n",
        "                                           bias=False)\n",
        "        \n",
        "        \n",
        "    def forward(self, x, i1, i2):\n",
        "        \n",
        "        # The third bottleneck\n",
        "        x = self.b31(x)\n",
        "        x = self.b32(x)\n",
        "        x = self.b33(x)\n",
        "        x = self.b34(x)\n",
        "        x = self.b35(x)\n",
        "        x = self.b36(x)\n",
        "        x = self.b37(x)\n",
        "        x = self.b38(x)\n",
        "        \n",
        "        # The fourth bottleneck\n",
        "        x = self.b40(x, i2)\n",
        "        x = self.b41(x)\n",
        "        x = self.b42(x)\n",
        "        \n",
        "        # The fifth bottleneck\n",
        "        x = self.b50(x, i1)\n",
        "        x = self.b51(x)\n",
        "        \n",
        "        # Final ConvTranspose Layer\n",
        "        x = self.fullconv(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ue6fHx87jhlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BranchedModule(nn.Module):\n",
        "    def __init__(self, C):\n",
        "        super(BranchedModule, self).__init__()\n",
        "        self.C = C\n",
        "        self.layer1 = ENetDecoder(C)\n",
        "        self.layer2 = ENetDecoder(C)\n",
        "        self.layer3 = ENetDecoder(C)\n",
        "        \n",
        "    def forward(self,x,i1,i2):\n",
        "        y = [self.layer1(x,i1,i2), self.layer2(x,i1,i2), self.layer3(x,i1,i2)]\n",
        "        return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJIZKwVPjhlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BranchedENet(nn.Module):\n",
        "    def __init__(self, C):\n",
        "        super().__init__()\n",
        "\n",
        "        # Define class variables\n",
        "        # C - number of classes\n",
        "        self.C = C\n",
        "        \n",
        "        # The initial block\n",
        "        self.init = InitialBlock()\n",
        "        \n",
        "        \n",
        "        # The first bottleneck\n",
        "        self.b10 = RDDNeck(dilation=1, \n",
        "                           in_channels=16, \n",
        "                           out_channels=64, \n",
        "                           down_flag=True, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b11 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b12 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b13 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        self.b14 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=64, \n",
        "                           down_flag=False, \n",
        "                           p=0.01)\n",
        "        \n",
        "        \n",
        "        # The second bottleneck\n",
        "        self.b20 = RDDNeck(dilation=1, \n",
        "                           in_channels=64, \n",
        "                           out_channels=128, \n",
        "                           down_flag=True)\n",
        "        \n",
        "        self.b21 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b22 = RDDNeck(dilation=2, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b23 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b24 = RDDNeck(dilation=4, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b25 = RDDNeck(dilation=1, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b26 = RDDNeck(dilation=8, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.b27 = ASNeck(in_channels=128, \n",
        "                          out_channels=128)\n",
        "        \n",
        "        self.b28 = RDDNeck(dilation=16, \n",
        "                           in_channels=128, \n",
        "                           out_channels=128, \n",
        "                           down_flag=False)\n",
        "        \n",
        "        self.branch = BranchedModule(C)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        # The initial block\n",
        "        x = self.init(x)\n",
        "        \n",
        "        # The first bottleneck\n",
        "        x, i1 = self.b10(x)\n",
        "        x = self.b11(x)\n",
        "        x = self.b12(x)\n",
        "        x = self.b13(x)\n",
        "        x = self.b14(x)\n",
        "\n",
        "         # the second bottleneck\n",
        "        x, i2 = self.b20(x)\n",
        "        x = self.b21(x)\n",
        "        x = self.b22(x)\n",
        "        x = self.b23(x)\n",
        "        x = self.b24(x)\n",
        "        x = self.b25(x)\n",
        "        x = self.b26(x)\n",
        "        x = self.b27(x)\n",
        "        x = self.b28(x)\n",
        "\n",
        "        x = self.branch(x, i1, i2)\n",
        "            \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoSdRBCAjhlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pretrained_model = torch.load('models/ckpt-enet.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpCP5JKAjhlW",
        "colab_type": "text"
      },
      "source": [
        "## 3 - Losses(todo)\n",
        "(1) Semantic Segmentation Loss\n",
        "\n",
        "(2) Instantance Segmentation Loss\n",
        "\n",
        "(3) Depth Estimation Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b6IvyXIjhlW",
        "colab_type": "code",
        "outputId": "ace7c895-c043-4152-d5a5-e9339ebf6854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"\n",
        "def compute_instance_cost(a_C, a_G):\n",
        "    M = {}\n",
        "    tools = require 'tools/tools'\n",
        "\n",
        "    in_margin = 0.5\n",
        "    out_margin = 1.5\n",
        "    Lnorm = 2\n",
        "\n",
        "    function norm(inp, L)\n",
        "        n\n",
        "        if (L == 1) then\n",
        "            n = torch.sum(torch.abs(inp), 1)\n",
        "        else\n",
        "            n = torch.sqrt(torch.sum(torch.pow(inp, 2), 1) + 1e-8)\n",
        "        end\n",
        "        return n\n",
        "    end\n",
        "\n",
        "    -- prediction: batchsize x nDim x h x w\n",
        "    -- labels: batchsize x classes x h x w\n",
        "\n",
        "    local lossf =\n",
        "        function(prediction, labels)\n",
        "        local batchsize = prediction:size(1)\n",
        "        local c = prediction:size(2)\n",
        "        local height = prediction:size(3)\n",
        "        local width = prediction:size(4)\n",
        "        local nInstanceMaps = labels:size(2)\n",
        "        local loss = 0\n",
        "\n",
        "        M.loss_dist = 0\n",
        "        M.loss_var = 0\n",
        "\n",
        "        for b = 1, batchsize do\n",
        "            local pred = prediction[b] -- c x h x w\n",
        "            local loss_var = 0\n",
        "            local loss_dist = 0\n",
        "\n",
        "            for h = 1, nInstanceMaps do\n",
        "                local label = labels[b][h]:view(1, height, width) -- 1 x h x w\n",
        "                local means = {}\n",
        "                local loss_v = 0\n",
        "                local loss_d = 0\n",
        "\n",
        "                -- center pull force\n",
        "                for j = 1, label:max() do\n",
        "                    local mask = label:eq(j)\n",
        "                    local mask_sum = mask:sum()\n",
        "                    if (mask_sum > 1) then\n",
        "                        local inst = pred[mask:expandAs(pred)]:view(c, -1, 1) -- c x -1 x 1\n",
        "\n",
        "                        -- Calculate mean of instance\n",
        "                        local mean = torch.mean(inst, 2) -- c x 1 x 1\n",
        "                        table.insert(means, mean)\n",
        "\n",
        "                        -- Calculate variance of instance\n",
        "                        local var = norm((inst - mean:expandAs(inst)), 2) -- 1 x -1 x 1\n",
        "                        var = torch.cmax(var - (in_margin), 0)\n",
        "                        local not_hinged = torch.sum(torch.gt(var, 0))\n",
        "\n",
        "                        var = torch.pow(var, 2)\n",
        "                        var = var:view(-1)\n",
        "\n",
        "                        var = torch.mean(var)\n",
        "                        loss_v = loss_v + var\n",
        "                    end\n",
        "                end\n",
        "\n",
        "                loss_var = loss_var + loss_v\n",
        "\n",
        "                -- center push force\n",
        "                if (#means > 1) then\n",
        "                    for j = 1, #means do\n",
        "                        local mean_A = means[j] -- c x 1 x 1\n",
        "                        for k = j + 1, #means do\n",
        "                            local mean_B = means[k] -- c x 1 x 1\n",
        "                            local d = norm(mean_A - mean_B, Lnorm) -- 1 x 1 x 1\n",
        "                            d = torch.pow(torch.cmax(-(d - 2 * out_margin), 0), 2)\n",
        "                            loss_d = loss_d + d[1][1][1]\n",
        "                        end\n",
        "                    end\n",
        "\n",
        "                    loss_dist = loss_dist + loss_d / ((#means - 1) + 1e-8)\n",
        "                end\n",
        "            end\n",
        "\n",
        "            loss = loss + (loss_dist + loss_var)\n",
        "        end\n",
        "\n",
        "        loss = loss / batchsize + torch.sum(prediction) * 0\n",
        "\n",
        "        return loss\n",
        "    end\n",
        "\n",
        "return lossf\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef compute_instance_cost(a_C, a_G):\\n    M = {}\\n    tools = require 'tools/tools'\\n\\n    in_margin = 0.5\\n    out_margin = 1.5\\n    Lnorm = 2\\n\\n    function norm(inp, L)\\n        n\\n        if (L == 1) then\\n            n = torch.sum(torch.abs(inp), 1)\\n        else\\n            n = torch.sqrt(torch.sum(torch.pow(inp, 2), 1) + 1e-8)\\n        end\\n        return n\\n    end\\n\\n    -- prediction: batchsize x nDim x h x w\\n    -- labels: batchsize x classes x h x w\\n\\n    local lossf =\\n        function(prediction, labels)\\n        local batchsize = prediction:size(1)\\n        local c = prediction:size(2)\\n        local height = prediction:size(3)\\n        local width = prediction:size(4)\\n        local nInstanceMaps = labels:size(2)\\n        local loss = 0\\n\\n        M.loss_dist = 0\\n        M.loss_var = 0\\n\\n        for b = 1, batchsize do\\n            local pred = prediction[b] -- c x h x w\\n            local loss_var = 0\\n            local loss_dist = 0\\n\\n            for h = 1, nInstanceMaps do\\n                local label = labels[b][h]:view(1, height, width) -- 1 x h x w\\n                local means = {}\\n                local loss_v = 0\\n                local loss_d = 0\\n\\n                -- center pull force\\n                for j = 1, label:max() do\\n                    local mask = label:eq(j)\\n                    local mask_sum = mask:sum()\\n                    if (mask_sum > 1) then\\n                        local inst = pred[mask:expandAs(pred)]:view(c, -1, 1) -- c x -1 x 1\\n\\n                        -- Calculate mean of instance\\n                        local mean = torch.mean(inst, 2) -- c x 1 x 1\\n                        table.insert(means, mean)\\n\\n                        -- Calculate variance of instance\\n                        local var = norm((inst - mean:expandAs(inst)), 2) -- 1 x -1 x 1\\n                        var = torch.cmax(var - (in_margin), 0)\\n                        local not_hinged = torch.sum(torch.gt(var, 0))\\n\\n                        var = torch.pow(var, 2)\\n                        var = var:view(-1)\\n\\n                        var = torch.mean(var)\\n                        loss_v = loss_v + var\\n                    end\\n                end\\n\\n                loss_var = loss_var + loss_v\\n\\n                -- center push force\\n                if (#means > 1) then\\n                    for j = 1, #means do\\n                        local mean_A = means[j] -- c x 1 x 1\\n                        for k = j + 1, #means do\\n                            local mean_B = means[k] -- c x 1 x 1\\n                            local d = norm(mean_A - mean_B, Lnorm) -- 1 x 1 x 1\\n                            d = torch.pow(torch.cmax(-(d - 2 * out_margin), 0), 2)\\n                            loss_d = loss_d + d[1][1][1]\\n                        end\\n                    end\\n\\n                    loss_dist = loss_dist + loss_d / ((#means - 1) + 1e-8)\\n                end\\n            end\\n\\n            loss = loss + (loss_dist + loss_var)\\n        end\\n\\n        loss = loss / batchsize + torch.sum(prediction) * 0\\n\\n        return loss\\n    end\\n\\nreturn lossf\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Dv3_I_Ljhla",
        "colab_type": "code",
        "outputId": "a4a00785-0446-46aa-edd0-6900a1d1a78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"\n",
        "def compute_huber_loss(input_i, label):\n",
        "    local mask = label:gt(0)\n",
        "    local d = input_i[mask] - label[mask]\n",
        "    local ds = d:size(1)\n",
        "\n",
        "    local da = torch.abs(d)\n",
        "    local d2 = torch.pow(d, 2)\n",
        "\n",
        "    local th = 1 / 5 * torch.max(da)\n",
        "    local mask2 = torch.gt(da, th)\n",
        "    da[mask2] = (d2[mask2] + (th * th)) / (2 * th)\n",
        "\n",
        "    return 1 / ds * torch.sum(da)\n",
        "\n",
        "return loss\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef compute_huber_loss(input_i, label):\\n    local mask = label:gt(0)\\n    local d = input_i[mask] - label[mask]\\n    local ds = d:size(1)\\n\\n    local da = torch.abs(d)\\n    local d2 = torch.pow(d, 2)\\n\\n    local th = 1 / 5 * torch.max(da)\\n    local mask2 = torch.gt(da, th)\\n    da[mask2] = (d2[mask2] + (th * th)) / (2 * th)\\n\\n    return 1 / ds * torch.sum(da)\\n\\nreturn loss\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHm_GLNBjhld",
        "colab_type": "code",
        "outputId": "3962711f-0616-4f3b-9570-426ec4902f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "\"\"\"local grad = require 'autograd'\n",
        "\n",
        "def lossfunction(lossf_name, weights):\n",
        "    if (lossf_name == 'softmaxLoss') then\n",
        "        lossfunction = cudnn.SpatialCrossEntropyCriterion(weights)\n",
        "    elseif (lossf_name == 'huberLoss') then\n",
        "        lossfunction = grad.nn.AutoCriterion('depthLoss_huber')(require 'lossf/myHuberLoss')\n",
        "    elseif (lossf_name == 'instanceLoss') then\n",
        "        lossfunction = grad.nn.AutoCriterion('instance_loss')(require 'lossf/myInstanceLoss')\n",
        "    else\n",
        "        assert(false, 'Cannot load lossfunction ' .. opts.lossf)\n",
        "    end\n",
        "\n",
        "    return lossfunction\n",
        "end\n",
        "\n",
        "return getLoss\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"local grad = require 'autograd'\\n\\ndef lossfunction(lossf_name, weights):\\n    if (lossf_name == 'softmaxLoss') then\\n        lossfunction = cudnn.SpatialCrossEntropyCriterion(weights)\\n    elseif (lossf_name == 'huberLoss') then\\n        lossfunction = grad.nn.AutoCriterion('depthLoss_huber')(require 'lossf/myHuberLoss')\\n    elseif (lossf_name == 'instanceLoss') then\\n        lossfunction = grad.nn.AutoCriterion('instance_loss')(require 'lossf/myInstanceLoss')\\n    else\\n        assert(false, 'Cannot load lossfunction ' .. opts.lossf)\\n    end\\n\\n    return lossfunction\\nend\\n\\nreturn getLoss\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnRAXNvbjhlf",
        "colab_type": "text"
      },
      "source": [
        "## 4 - Instantiate the ENet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zo6pIjqjhlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enet = BranchedENet(12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQAvwXDpjhlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
        "device = torch.device('cuda:0')\n",
        "#device = torch.device('cpu')\n",
        "enet = enet.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxnljE48jhlm",
        "colab_type": "text"
      },
      "source": [
        "## 5 - Define the loader that will load the input and output images(todo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S-PxeTpjhln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loader(training_path, segmented_path, batch_size, h=320, w=1000):\n",
        "    filenames_t = os.listdir(training_path)\n",
        "    total_files_t = len(filenames_t)\n",
        "    \n",
        "    filenames_s = os.listdir(segmented_path)\n",
        "    total_files_s = len(filenames_s)\n",
        "    \n",
        "    assert(total_files_t == total_files_s)\n",
        "    \n",
        "    if str(batch_size).lower() == 'all':\n",
        "        batch_size = total_files_s\n",
        "    \n",
        "    idx = 0\n",
        "    while(1):\n",
        "      # Choosing random indexes of images and labels\n",
        "        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
        "            \n",
        "        \n",
        "        inputs = []\n",
        "        labels = []\n",
        "        \n",
        "        for jj in batch_idxs:\n",
        "          # Reading normalized photo\n",
        "            img = plt.imread(training_path + filenames_t[jj])\n",
        "          # Resizing using nearest neighbor method\n",
        "            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
        "            inputs.append(img)\n",
        "          \n",
        "          # Reading semantic image\n",
        "            img = Image.open(segmented_path + filenames_s[jj])\n",
        "            img = np.array(img)\n",
        "          # Resizing using nearest neighbor method\n",
        "            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
        "            labels.append(img)\n",
        "         \n",
        "        inputs = np.stack(inputs, axis=2)\n",
        "      # Changing image format to C x H x W\n",
        "        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
        "        \n",
        "        labels = torch.tensor(labels)\n",
        "        \n",
        "        yield inputs, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jyRzVwcjhlq",
        "colab_type": "text"
      },
      "source": [
        "## 6 - Define the class weights(todo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIrH8GkZjhlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_class_weights(num_classes, c=1.02):\n",
        "    pipe = loader('images/train/', 'images/trainannot/', batch_size='all')\n",
        "    _, labels = next(pipe)\n",
        "    all_labels = labels.flatten()\n",
        "    print(all_labels)\n",
        "    each_class = np.bincount(all_labels, minlength=num_classes)\n",
        "    prospensity_score = each_class / len(all_labels)\n",
        "    class_weights = 1 / (np.log(c + prospensity_score))\n",
        "    return class_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsxpISPxjhlt",
        "colab_type": "code",
        "outputId": "52801f79-e36a-4bb2-c913-411ac22483a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "class_weights = get_class_weights(12)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 1, 1,  ..., 3, 3, 3], dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlATaBtjjhlw",
        "colab_type": "text"
      },
      "source": [
        "## 7 - Define the Hyperparameters(todo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDZLtYRbjhlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 5e-4\n",
        "batch_size = 1\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
        "optimizer = torch.optim.Adam(enet.parameters(), \n",
        "                             lr=lr,\n",
        "                             weight_decay=2e-4)\n",
        "\n",
        "print_every = 5\n",
        "eval_every = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Odil0dEjhlz",
        "colab_type": "text"
      },
      "source": [
        "## 8 - Training loop(todo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgTjjlmxjhlz",
        "colab_type": "code",
        "outputId": "d1272f7a-1d7e-4ceb-f8ca-68e6748cf0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "ef1e273f3b2043b192bf81d8f4e124c5",
            "c6d5811378a4442aa4b699e457cadb69",
            "ca676c3ef7ca4d82b99142c3a287ecb7",
            "3b32064c3e2b45f9b67b2eb7c2b2bc93",
            "94113c6f17df4fa5999df7d94523af1e",
            "f41f55ceab4940c8a1533c347a19a4f2",
            "cdc46da27c4444e0b0e6f0fd8388a1b1",
            "88552b181b5f41aa94a1ca52e3bca36d"
          ]
        }
      },
      "source": [
        "train_losses = []\n",
        "eval_losses = []\n",
        "\n",
        "bc_train = 367 // batch_size # mini_batch train\n",
        "bc_eval = 101 // batch_size  # mini_batch validation\n",
        "\n",
        "# Define pipeline objects\n",
        "pipe = loader('images/train/', 'images/trainannot/', batch_size)\n",
        "eval_pipe = loader('images/val/', 'images/valannot/', batch_size)\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "# Train loop\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    \n",
        "    \n",
        "    train_loss = 0\n",
        "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
        "    \n",
        "    enet.train()\n",
        "    \n",
        "    for _ in tqdm(range(bc_train)):\n",
        "        X_batch, mask_batch = next(pipe)\n",
        "        \n",
        "        # assign data to cpu/gpu\n",
        "        X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        out = enet(X_batch.float())\n",
        "\n",
        "        # loss calculation for depth\n",
        "        loss = criterion(out[0], mask_batch.long())\n",
        "        # update weights\n",
        "        loss.backward(retain_graph=True)\n",
        "        #optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        # loss calculation for class instance\n",
        "        loss = criterion(out[1], mask_batch.long())\n",
        "        # update weights\n",
        "        loss.backward(retain_graph=True)\n",
        "        #optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # loss calculation for class segmentation\n",
        "        loss = criterion(out[2], mask_batch.long())\n",
        "        # update weights\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "\n",
        "    print ()\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    if (e+1) % print_every == 0:\n",
        "        print ('Epoch {}/{}...'.format(e, epochs),\n",
        "                'Loss {:6f}'.format(train_loss))\n",
        "    \n",
        "    if e % eval_every == 0:\n",
        "        with torch.no_grad():\n",
        "            enet.eval()\n",
        "            \n",
        "            eval_loss = 0\n",
        "\n",
        "            # Validation loop\n",
        "            for _ in tqdm(range(bc_eval)):\n",
        "                inputs, labels = next(eval_pipe)\n",
        "\n",
        "                \n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    \n",
        "                \n",
        "                out = enet(inputs)\n",
        "                \n",
        "                out = out.data.max(1)[1]\n",
        "                \n",
        "                eval_loss += (labels.long() - out.long()).sum()\n",
        "                \n",
        "            \n",
        "            print ()\n",
        "            print ('Loss {:6f}'.format(eval_loss))\n",
        "            \n",
        "            eval_losses.append(eval_loss)\n",
        "        \n",
        "    if e % print_every == 0:\n",
        "        checkpoint = {\n",
        "            'epochs' : e,\n",
        "            'state_dict' : enet.state_dict()\n",
        "        }\n",
        "        torch.save(checkpoint, '/content/ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
        "        print ('Model saved!')\n",
        "\n",
        "print ('Epoch {}/{}...'.format(e, epochs),\n",
        "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------- Epoch 1 ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef1e273f3b2043b192bf81d8f4e124c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=367), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-6625974ab990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UELZ5ghjhl2",
        "colab_type": "code",
        "outputId": "92120683-83af-44b1-ce71-ad275a5414c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(F)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<module 'torch.nn.functional' from '/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnJmyQw9b1jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
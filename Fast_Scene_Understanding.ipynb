{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wrqIinejhkt"
   },
   "outputs": [],
   "source": [
    "import zipfile as zf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from PIL import Image\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bNQ-SAqjhky"
   },
   "source": [
    "## 1 - Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M24VBWq_jhkz"
   },
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/pxcz2wdz04zxocq/CamVid.zip?dl=1 -O CamVid.zip\n",
    "#!unzip CamVid.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WdA2ZHq4jhk2"
   },
   "outputs": [],
   "source": [
    "#!unzip CamVid.zip -d images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o-dj3wA0jhk5"
   },
   "source": [
    "## 2 - Create the ENet model\n",
    "\n",
    "We decided to model following residual blocks as separate class to model ENET encoder and decoder:\n",
    "    - Initial block\n",
    "    - RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
    "    - ASNeck - class for asymetric bottlenecks\n",
    "    - UBNeck - class for upsampling bottlenecks\n",
    "\n",
    "ENET architecture is autoencoder based model and is divided into 5 sub-blocks. Pleas refer [ENET paper](https://arxiv.org/pdf/1606.02147.pdf) for details of each sub-block. ENET building blocks code is taken from [here](https://github.com/iArunava/ENet-Real-Time-Semantic-Segmentation).\n",
    "\n",
    "Fast scene understanding uses first 2 sub-blocks as encoder and remaining 3 as decoder. In this implemantation, there is 1 shared encoder and 3 separate decoder for 3 tasks(instance segementation, semantic segmentation, Depth estimation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ENetDecoder import ENetDecoder\n",
    "from models.ENetEncoder import ENetEncoder\n",
    "\n",
    "class BranchedENet(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        # C - number of classes\n",
    "        self.C = C\n",
    "        \n",
    "        self.enc = ENetEncoder(C)\n",
    "        \n",
    "        self.dec1 = ENetDecoder(C)\n",
    "        self.dec2 = ENetDecoder(C)\n",
    "        self.dec3 = ENetDecoder(C)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Output of Encoder\n",
    "        x, i1, i2 = self.enc(x)\n",
    "        # output of all 3 decoder in list\n",
    "        x = [self.dec1(x, i1, i2), self.dec2(x, i1, i2), self.dec3(x, i1, i2)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SoSdRBCAjhlU"
   },
   "outputs": [],
   "source": [
    "#pretrained_model = torch.load('models/ckpt-enet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpCP5JKAjhlW"
   },
   "source": [
    "## 3 - Losses(todo)\n",
    "(1) Semantic Segmentation Loss\n",
    "\n",
    "(2) Instantance Segmentation Loss\n",
    "\n",
    "(3) Depth Estimation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "0b6IvyXIjhlW",
    "outputId": "ace7c895-c043-4152-d5a5-e9339ebf6854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef compute_instance_cost(a_C, a_G):\\n    M = {}\\n    tools = require 'tools/tools'\\n\\n    in_margin = 0.5\\n    out_margin = 1.5\\n    Lnorm = 2\\n\\n    function norm(inp, L)\\n        n\\n        if (L == 1) then\\n            n = torch.sum(torch.abs(inp), 1)\\n        else\\n            n = torch.sqrt(torch.sum(torch.pow(inp, 2), 1) + 1e-8)\\n        end\\n        return n\\n    end\\n\\n    -- prediction: batchsize x nDim x h x w\\n    -- labels: batchsize x classes x h x w\\n\\n    local lossf =\\n        function(prediction, labels)\\n        local batchsize = prediction:size(1)\\n        local c = prediction:size(2)\\n        local height = prediction:size(3)\\n        local width = prediction:size(4)\\n        local nInstanceMaps = labels:size(2)\\n        local loss = 0\\n\\n        M.loss_dist = 0\\n        M.loss_var = 0\\n\\n        for b = 1, batchsize do\\n            local pred = prediction[b] -- c x h x w\\n            local loss_var = 0\\n            local loss_dist = 0\\n\\n            for h = 1, nInstanceMaps do\\n                local label = labels[b][h]:view(1, height, width) -- 1 x h x w\\n                local means = {}\\n                local loss_v = 0\\n                local loss_d = 0\\n\\n                -- center pull force\\n                for j = 1, label:max() do\\n                    local mask = label:eq(j)\\n                    local mask_sum = mask:sum()\\n                    if (mask_sum > 1) then\\n                        local inst = pred[mask:expandAs(pred)]:view(c, -1, 1) -- c x -1 x 1\\n\\n                        -- Calculate mean of instance\\n                        local mean = torch.mean(inst, 2) -- c x 1 x 1\\n                        table.insert(means, mean)\\n\\n                        -- Calculate variance of instance\\n                        local var = norm((inst - mean:expandAs(inst)), 2) -- 1 x -1 x 1\\n                        var = torch.cmax(var - (in_margin), 0)\\n                        local not_hinged = torch.sum(torch.gt(var, 0))\\n\\n                        var = torch.pow(var, 2)\\n                        var = var:view(-1)\\n\\n                        var = torch.mean(var)\\n                        loss_v = loss_v + var\\n                    end\\n                end\\n\\n                loss_var = loss_var + loss_v\\n\\n                -- center push force\\n                if (#means > 1) then\\n                    for j = 1, #means do\\n                        local mean_A = means[j] -- c x 1 x 1\\n                        for k = j + 1, #means do\\n                            local mean_B = means[k] -- c x 1 x 1\\n                            local d = norm(mean_A - mean_B, Lnorm) -- 1 x 1 x 1\\n                            d = torch.pow(torch.cmax(-(d - 2 * out_margin), 0), 2)\\n                            loss_d = loss_d + d[1][1][1]\\n                        end\\n                    end\\n\\n                    loss_dist = loss_dist + loss_d / ((#means - 1) + 1e-8)\\n                end\\n            end\\n\\n            loss = loss + (loss_dist + loss_var)\\n        end\\n\\n        loss = loss / batchsize + torch.sum(prediction) * 0\\n\\n        return loss\\n    end\\n\\nreturn lossf\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def compute_instance_cost(a_C, a_G):\n",
    "    M = {}\n",
    "    tools = require 'tools/tools'\n",
    "\n",
    "    in_margin = 0.5\n",
    "    out_margin = 1.5\n",
    "    Lnorm = 2\n",
    "\n",
    "    function norm(inp, L)\n",
    "        n\n",
    "        if (L == 1) then\n",
    "            n = torch.sum(torch.abs(inp), 1)\n",
    "        else\n",
    "            n = torch.sqrt(torch.sum(torch.pow(inp, 2), 1) + 1e-8)\n",
    "        end\n",
    "        return n\n",
    "    end\n",
    "\n",
    "    -- prediction: batchsize x nDim x h x w\n",
    "    -- labels: batchsize x classes x h x w\n",
    "\n",
    "    local lossf =\n",
    "        function(prediction, labels)\n",
    "        local batchsize = prediction:size(1)\n",
    "        local c = prediction:size(2)\n",
    "        local height = prediction:size(3)\n",
    "        local width = prediction:size(4)\n",
    "        local nInstanceMaps = labels:size(2)\n",
    "        local loss = 0\n",
    "\n",
    "        M.loss_dist = 0\n",
    "        M.loss_var = 0\n",
    "\n",
    "        for b = 1, batchsize do\n",
    "            local pred = prediction[b] -- c x h x w\n",
    "            local loss_var = 0\n",
    "            local loss_dist = 0\n",
    "\n",
    "            for h = 1, nInstanceMaps do\n",
    "                local label = labels[b][h]:view(1, height, width) -- 1 x h x w\n",
    "                local means = {}\n",
    "                local loss_v = 0\n",
    "                local loss_d = 0\n",
    "\n",
    "                -- center pull force\n",
    "                for j = 1, label:max() do\n",
    "                    local mask = label:eq(j)\n",
    "                    local mask_sum = mask:sum()\n",
    "                    if (mask_sum > 1) then\n",
    "                        local inst = pred[mask:expandAs(pred)]:view(c, -1, 1) -- c x -1 x 1\n",
    "\n",
    "                        -- Calculate mean of instance\n",
    "                        local mean = torch.mean(inst, 2) -- c x 1 x 1\n",
    "                        table.insert(means, mean)\n",
    "\n",
    "                        -- Calculate variance of instance\n",
    "                        local var = norm((inst - mean:expandAs(inst)), 2) -- 1 x -1 x 1\n",
    "                        var = torch.cmax(var - (in_margin), 0)\n",
    "                        local not_hinged = torch.sum(torch.gt(var, 0))\n",
    "\n",
    "                        var = torch.pow(var, 2)\n",
    "                        var = var:view(-1)\n",
    "\n",
    "                        var = torch.mean(var)\n",
    "                        loss_v = loss_v + var\n",
    "                    end\n",
    "                end\n",
    "\n",
    "                loss_var = loss_var + loss_v\n",
    "\n",
    "                -- center push force\n",
    "                if (#means > 1) then\n",
    "                    for j = 1, #means do\n",
    "                        local mean_A = means[j] -- c x 1 x 1\n",
    "                        for k = j + 1, #means do\n",
    "                            local mean_B = means[k] -- c x 1 x 1\n",
    "                            local d = norm(mean_A - mean_B, Lnorm) -- 1 x 1 x 1\n",
    "                            d = torch.pow(torch.cmax(-(d - 2 * out_margin), 0), 2)\n",
    "                            loss_d = loss_d + d[1][1][1]\n",
    "                        end\n",
    "                    end\n",
    "\n",
    "                    loss_dist = loss_dist + loss_d / ((#means - 1) + 1e-8)\n",
    "                end\n",
    "            end\n",
    "\n",
    "            loss = loss + (loss_dist + loss_var)\n",
    "        end\n",
    "\n",
    "        loss = loss / batchsize + torch.sum(prediction) * 0\n",
    "\n",
    "        return loss\n",
    "    end\n",
    "\n",
    "return lossf\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "4Dv3_I_Ljhla",
    "outputId": "a4a00785-0446-46aa-edd0-6900a1d1a78d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_huber_loss(input_i, label):\\n    local mask = label:gt(0)\\n    local d = input_i[mask] - label[mask]\\n    local ds = d:size(1)\\n\\n    local da = torch.abs(d)\\n    local d2 = torch.pow(d, 2)\\n\\n    local th = 1 / 5 * torch.max(da)\\n    local mask2 = torch.gt(da, th)\\n    da[mask2] = (d2[mask2] + (th * th)) / (2 * th)\\n\\n    return 1 / ds * torch.sum(da)\\n\\nreturn loss\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def compute_huber_loss(input_i, label):\n",
    "    local mask = label:gt(0)\n",
    "    local d = input_i[mask] - label[mask]\n",
    "    local ds = d:size(1)\n",
    "\n",
    "    local da = torch.abs(d)\n",
    "    local d2 = torch.pow(d, 2)\n",
    "\n",
    "    local th = 1 / 5 * torch.max(da)\n",
    "    local mask2 = torch.gt(da, th)\n",
    "    da[mask2] = (d2[mask2] + (th * th)) / (2 * th)\n",
    "\n",
    "    return 1 / ds * torch.sum(da)\n",
    "\n",
    "return loss\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "lHm_GLNBjhld",
    "outputId": "3962711f-0616-4f3b-9570-426ec4902f9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"local grad = require 'autograd'\\n\\ndef lossfunction(lossf_name, weights):\\n    if (lossf_name == 'softmaxLoss') then\\n        lossfunction = cudnn.SpatialCrossEntropyCriterion(weights)\\n    elseif (lossf_name == 'huberLoss') then\\n        lossfunction = grad.nn.AutoCriterion('depthLoss_huber')(require 'lossf/myHuberLoss')\\n    elseif (lossf_name == 'instanceLoss') then\\n        lossfunction = grad.nn.AutoCriterion('instance_loss')(require 'lossf/myInstanceLoss')\\n    else\\n        assert(false, 'Cannot load lossfunction ' .. opts.lossf)\\n    end\\n\\n    return lossfunction\\nend\\n\\nreturn getLoss\""
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"local grad = require 'autograd'\n",
    "\n",
    "def lossfunction(lossf_name, weights):\n",
    "    if (lossf_name == 'softmaxLoss') then\n",
    "        lossfunction = cudnn.SpatialCrossEntropyCriterion(weights)\n",
    "    elseif (lossf_name == 'huberLoss') then\n",
    "        lossfunction = grad.nn.AutoCriterion('depthLoss_huber')(require 'lossf/myHuberLoss')\n",
    "    elseif (lossf_name == 'instanceLoss') then\n",
    "        lossfunction = grad.nn.AutoCriterion('instance_loss')(require 'lossf/myInstanceLoss')\n",
    "    else\n",
    "        assert(false, 'Cannot load lossfunction ' .. opts.lossf)\n",
    "    end\n",
    "\n",
    "    return lossfunction\n",
    "end\n",
    "\n",
    "return getLoss\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnRAXNvbjhlf"
   },
   "source": [
    "## 4 - Instantiate the ENet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Zo6pIjqjhlg"
   },
   "outputs": [],
   "source": [
    "enet = BranchedENet(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQAvwXDpjhlj"
   },
   "outputs": [],
   "source": [
    "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
    "device = torch.device('cuda:0')\n",
    "#device = torch.device('cpu')\n",
    "enet = enet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxnljE48jhlm"
   },
   "source": [
    "## 5 - Define the loader that will load the input and output images(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S-PxeTpjhln"
   },
   "outputs": [],
   "source": [
    "def loader(training_path, segmented_path, batch_size, h=320, w=1000):\n",
    "    filenames_t = os.listdir(training_path)\n",
    "    total_files_t = len(filenames_t)\n",
    "    \n",
    "    filenames_s = os.listdir(segmented_path)\n",
    "    total_files_s = len(filenames_s)\n",
    "    \n",
    "    assert(total_files_t == total_files_s)\n",
    "    \n",
    "    if str(batch_size).lower() == 'all':\n",
    "        batch_size = total_files_s\n",
    "    \n",
    "    idx = 0\n",
    "    while(1):\n",
    "      # Choosing random indexes of images and labels\n",
    "        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
    "            \n",
    "        \n",
    "        inputs = []\n",
    "        labels = []\n",
    "        \n",
    "        for jj in batch_idxs:\n",
    "          # Reading normalized photo\n",
    "            img = plt.imread(training_path + filenames_t[jj])\n",
    "          # Resizing using nearest neighbor method\n",
    "            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "            inputs.append(img)\n",
    "          \n",
    "          # Reading semantic image\n",
    "            img = Image.open(segmented_path + filenames_s[jj])\n",
    "            img = np.array(img)\n",
    "          # Resizing using nearest neighbor method\n",
    "            img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "            labels.append(img)\n",
    "         \n",
    "        inputs = np.stack(inputs, axis=2)\n",
    "      # Changing image format to C x H x W\n",
    "        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
    "        \n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        yield inputs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jyRzVwcjhlq"
   },
   "source": [
    "## 6 - Define the class weights(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uIrH8GkZjhlr"
   },
   "outputs": [],
   "source": [
    "def get_class_weights(num_classes, c=1.02):\n",
    "    pipe = loader('images/train/', 'images/trainannot/', batch_size='all')\n",
    "    _, labels = next(pipe)\n",
    "    all_labels = labels.flatten()\n",
    "    print(all_labels)\n",
    "    each_class = np.bincount(all_labels, minlength=num_classes)\n",
    "    prospensity_score = each_class / len(all_labels)\n",
    "    class_weights = 1 / (np.log(c + prospensity_score))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "IsxpISPxjhlt",
    "outputId": "52801f79-e36a-4bb2-c913-411ac22483a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1,  ..., 3, 3, 3], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "class_weights = get_class_weights(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hlATaBtjjhlw"
   },
   "source": [
    "## 7 - Define the Hyperparameters(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDZLtYRbjhlw"
   },
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(enet.parameters(), \n",
    "                             lr=lr,\n",
    "                             weight_decay=2e-4)\n",
    "\n",
    "print_every = 5\n",
    "eval_every = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Odil0dEjhlz"
   },
   "source": [
    "## 8 - Training loop(todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418,
     "referenced_widgets": [
      "ef1e273f3b2043b192bf81d8f4e124c5",
      "c6d5811378a4442aa4b699e457cadb69",
      "ca676c3ef7ca4d82b99142c3a287ecb7",
      "3b32064c3e2b45f9b67b2eb7c2b2bc93",
      "94113c6f17df4fa5999df7d94523af1e",
      "f41f55ceab4940c8a1533c347a19a4f2",
      "cdc46da27c4444e0b0e6f0fd8388a1b1",
      "88552b181b5f41aa94a1ca52e3bca36d"
     ]
    },
    "colab_type": "code",
    "id": "PgTjjlmxjhlz",
    "outputId": "d1272f7a-1d7e-4ceb-f8ca-68e6748cf0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1e273f3b2043b192bf81d8f4e124c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=367), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6625974ab990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "bc_train = 367 // batch_size # mini_batch train\n",
    "bc_eval = 101 // batch_size  # mini_batch validation\n",
    "\n",
    "# Define pipeline objects\n",
    "pipe = loader('images/train/', 'images/trainannot/', batch_size)\n",
    "eval_pipe = loader('images/val/', 'images/valannot/', batch_size)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# Train loop\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    \n",
    "    \n",
    "    train_loss = 0\n",
    "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
    "    \n",
    "    enet.train()\n",
    "    \n",
    "    for _ in tqdm(range(bc_train)):\n",
    "        X_batch, mask_batch = next(pipe)\n",
    "        \n",
    "        # assign data to cpu/gpu\n",
    "        X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = enet(X_batch.float())\n",
    "\n",
    "        # loss calculation for depth\n",
    "        loss = criterion(out[0], mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        #optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # loss calculation for class instance\n",
    "        loss = criterion(out[1], mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward(retain_graph=True)\n",
    "        #optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # loss calculation for class segmentation\n",
    "        loss = criterion(out[2], mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "\n",
    "    print ()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (e+1) % print_every == 0:\n",
    "        print ('Epoch {}/{}...'.format(e, epochs),\n",
    "                'Loss {:6f}'.format(train_loss))\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        with torch.no_grad():\n",
    "            enet.eval()\n",
    "            \n",
    "            eval_loss = 0\n",
    "\n",
    "            # Validation loop\n",
    "            for _ in tqdm(range(bc_eval)):\n",
    "                inputs, labels = next(eval_pipe)\n",
    "\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    \n",
    "                \n",
    "                out = enet(inputs)\n",
    "                \n",
    "                out = out.data.max(1)[1]\n",
    "                \n",
    "                eval_loss += (labels.long() - out.long()).sum()\n",
    "                \n",
    "            \n",
    "            print ()\n",
    "            print ('Loss {:6f}'.format(eval_loss))\n",
    "            \n",
    "            eval_losses.append(eval_loss)\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : enet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, '/content/ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
    "        print ('Model saved!')\n",
    "\n",
    "print ('Epoch {}/{}...'.format(e, epochs),\n",
    "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "2UELZ5ghjhl2",
    "outputId": "92120683-83af-44b1-ce71-ad275a5414c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.nn.functional' from '/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py'>\n"
     ]
    }
   ],
   "source": [
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnJmyQw9b1jm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fast Scene Understanding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3b32064c3e2b45f9b67b2eb7c2b2bc93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88552b181b5f41aa94a1ca52e3bca36d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cdc46da27c4444e0b0e6f0fd8388a1b1",
      "value": " 62/367 [00:17&lt;01:22,  3.70it/s]"
     }
    },
    "88552b181b5f41aa94a1ca52e3bca36d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94113c6f17df4fa5999df7d94523af1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c6d5811378a4442aa4b699e457cadb69": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca676c3ef7ca4d82b99142c3a287ecb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 17%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f41f55ceab4940c8a1533c347a19a4f2",
      "max": 367,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_94113c6f17df4fa5999df7d94523af1e",
      "value": 62
     }
    },
    "cdc46da27c4444e0b0e6f0fd8388a1b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef1e273f3b2043b192bf81d8f4e124c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca676c3ef7ca4d82b99142c3a287ecb7",
       "IPY_MODEL_3b32064c3e2b45f9b67b2eb7c2b2bc93"
      ],
      "layout": "IPY_MODEL_c6d5811378a4442aa4b699e457cadb69"
     }
    },
    "f41f55ceab4940c8a1533c347a19a4f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
